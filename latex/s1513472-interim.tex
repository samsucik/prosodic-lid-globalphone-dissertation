\documentclass[bsc,frontabs,twoside,singlespacing,parskip,deptreport]{infthesis}

\usepackage[round]{natbib}
\usepackage[hidelinks]{hyperref}

\begin{document}

\title{Prosodic features in state-of-the-art spoken language identification}

\author{Sam Sucik}

\course{Master of Informatics}
\project{{\bf MInf Project (Part 1) Report}}

\date{\today}

\abstract{
  TO-DO
}

\maketitle

% Add acknowledgements if necessary.
\section*{Acknowledgements}{
  Thanks to Paul Moore for productive collaboration while building the baseline system, to Steve Renals for his supervision and optimism, and to David Snyder for his advice.
}

\tableofcontents

%\pagenumbering{arabic}


\chapter{Introduction}{
  \section{Motivation}{
    LID is useful in ASR, in voice assistants, emergency call routing, etc.
    Traditionally, acoustic features are used (influence of ASR on LID and SID). Prosodic LID is much rarer, although results show that prosodic information can help identify language \citep{Lin_et_al_2005}, and that both LID and ASR can benefit from using acoustic \textit{and} prosodic features \citep{Martinez_et_al_2013,Ghahremani_et_al_2014}.
    Just last year, a novel architecture for LID was proposed by \cite{Snyder_et_al_2018}, dramatically improving the state-of-the-art results. Although the authors find that using bottleneck features from an ASR DNN yields better results than using the standard acoustic MFCC features, even the ASR DNN was trained just using MFCCs. Thus the work ignores the potential of speech information other than that captured by MFCCs.
  }
  \section{Aims}{
    In this work, I aim to reproduce the state-of-the-art LID system and explore the use of prosodic features in addition to acoustic ones. Because the system uses a relatively novel architecture, in which a TDNN aggregates information across a speech segment, I also compare two types of acoustic features, one which has such aggregation over time encoded (SDC) and one that only containes information about single frames (vanilla MFCC).
  }
  \section{Contributions}{
    what exactly I did
    adapted SRE implementation for LID
    researched literature concerning prosodic LID
    built a system that has the potential to become open source as part of the Kaldi toolkit, to be used by a wider community
  }
  \section{Overview}{
    structure of the report
  }
}

\chapter{Background}{
  Definitions (interespersed, not having a separate section)
    LID, identification vs verification
    acoustic (MFCC, SDC) vs prosodic (intonation, stress, rhythm) LID
    other definitions added later as needed

  \section{Spoken language identification}{

  }
  \section{Traditional approaches}{
    GMMs and i-vectors
  }
  \section{State of the art}{
    TDNNs and x-vectors
  }
  \section{Features used for LID}{
    Acoustic
      MFCCs (vanilla and with delta terms)
      SDCs
    Prosodic
      F0 (intonation), and KaldiPitch
      Energy (stress)
      Duration (rhythm)
  }
}

\chapter{Data}{
  Intro: Popular datasets
  \section{GlobalPhone}{

  }
  \section{Data partitioning}{
    explanation of the use of training/enrollment/evaluation/testing data
  }
  \section{Data preprocessing}{
    SHN to WAV
    splitting long utterances into shorter ones
  }
}

\chapter{Implementation}{
  \section{The Kaldi toolkit}{

  }
  \section{Adapted implementations}{
    Snyder et al.'s LID x-vector paper
    GlobalPhone recipe
    SRE16 recipe
  }
  \section{Final architecture}{
    Description of x-vector+GP architecture (highlighting own contributions)
    how the whole pipeline works: go into much more detail than in the Related work section
    mention possibility of direct classification with TDNN and that I focus on using independent classifier because it provides extra flexibility
  }
  \section{Computing environment}{
    cluster, Slurm, GPUs, parallelisation, rough runtimes of the different stages
  }
  \section{Hyperparameters}{
    tuned on the baseline (see next section)
    decided: TDNN layers, activation function, learning algorithm (TO-DO: understand shrinking), log-regression parameters
    empirically established: number of TDNN training epochs (also mention training time)
  }
}

\chapter{Experiments}{
  Intro: I will compare acoustic and prosodic features, leaving formants and BNF for later.
  Evaluation metric: $C_primary$

  \section{Baseline}{
    vanilla MFCCs (expand on MFCC configuration)
    30s enrollment segments, 10s eval/test segments
  }
  \section{SDC vectors}{
    wanna compare with MFCCs
  }
  \section{KaldiPitch+Energy vectors}{

  }
  \section{MFCC/SDC + KaldiPitch+Energy}{
    feature vectors concatenated, wanna see if they are complementary
  }
  \section{Possibly fusion of MFCC/SDC and KaldiPitch+Energy scores}{
    fucion of results instead of feature vectors
    using evaluation data for training the fusion logistic regression
  }
}

\chapter{Results}{
  Reported: overall $C_primary$, language-specific score, accuracy (for illustrative purposes), confusion matrix (to see which language pairs are confusing)
  Focus on Slavic languages (Czech, Croatian, Polish, Russian, Bulgarian)
}

\chapter{Discussion}{
  
}

\chapter{Future work}{
  \section{Plans for Part 2 of the MInf project}{

  }
  \section{Other future ideas}{

  }
}

\chapter{Conclusions}{
  
}

% use the following and \cite{} as above if you use BibTeX
% otherwise generate bibtem entries
\bibliographystyle{apalike}
\bibliography{s1513472-interim}

\end{document}
