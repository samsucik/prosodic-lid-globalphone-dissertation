\documentclass[bsc,frontabs,twoside,singlespacing,parskip,deptreport]{infthesis}

\usepackage[round]{natbib}
\usepackage[hidelinks]{hyperref}

\begin{document}

\title{Language Identification from Speech}

\author{Sam Sucik}

\course{Master of Informatics}
\project{{\bf MInf Project (Part 1) Report}}

\date{\today}

\abstract{
  This is an example of {\tt infthesis} style.
  The file {\tt skeleton.tex} generates this document and can be 
  used to get a ``skeleton'' for your thesis.
  The abstract should summarise your report and fit in the space on the 
  first page.
  %
  You may, of course, use any other software to write your report,
  as long as you follow the same style. That means: producing a title
  page as given here, and including a table of contents and bibliography.
}

\maketitle

% Add acknowledgements if necessary.
\section*{Acknowledgements}{
  Thanks to Paul Moore for productive collaboration while building the baseline system, to Steve Renals for his guidance, feedback and optimism, and to David Snyder for his advice.
}

\tableofcontents

%\pagenumbering{arabic}


\chapter{Introduction}{

}

\chapter{Building the System}{
  System was built in Kaldi \citep{Povey_et_al_2011}.
  Reproducing the architecture described by Snyder et al. in LID setting \citep{Snyder_et_al_2018}. The authors adapted the architecture from the speaker recognition setting \citep{Snyder_et_al_2018b}, which is accessible as the SRE16 recipe in Kaldi. We used that recipe and the GlobalPhone Kaldi recipe.
  
  \section{Choice of classifier}{
    The SRE16 recipe uses PLDA because it does not do identification, but verification. For our purposes, we needed a proper classifier. Current popular and well-performing classifiers are various flavours of GMM and logistic regression, with no clear winner. \cite{Snyder_et_al_2018}, for instance, used GMM trained using MMI -- based on \cite{McCree_2014}. We decided to re-use a model which is already implemented in the LRE07/v2 recipe -- logistic regression. Our decision was also consulted with \cite{Snyder_2018_kaldi-help}.
  }
  
  \section{Setting Hyperparameters}{
    \begin{enumerate}
    \item MFCC extraction parameters
    \item DNN architecture: Layers, activation functions, choice of extraction layer, ...
    \item DNN training: Learning algorithm and its parameters, number of epochs, ...
    \item 
    \end{enumerate}
  }
}

\chapter{Features for LID}{
  \section{Acoustic Features}{

  }
  \section{Prosodic Features}{

  }
  \section{Features used in literature}{
    Various features used in the past in LID experiments:
    \begin{enumerate}
    \item{Shifted delta cepstra (SDC) by \cite{Ferrer_et_al_2016} and \cite{Sarma_et_al_2018} (7D MFCC + 7-1-3-7 SDCs = 56D) and by \cite{Torres-Carrasquillo_et_al_2002} (10-1-3-3), }
    \item{19 MFCCs + energy + 20 $\Delta$ + 20 $\Delta\Delta$ = 60D by \cite{Sarma_et_al_2018} -- outperformed by SDCs, but note that they trained an ASR TDNN for generating i-vectors}
    \item{39D MFCC vectors combined with 4D pitch features \citep{Song_et_al_2013}}
    \item{39 PLP features (including $\Delta$ and $\Delta\Delta$) \citep{Lopez-Moreno_et_al_2014}}
    \item{\cite{Lin_et_al_2005} do LID just from the pitch contour parametrised by Legendre polynomials}
    \item{\cite{Ghahremani_et_al_2014} show ASR improvements with a pitch-tracking algorithm that calculates pitch even for unvoiced frames}
    \end{enumerate}
  }
  \section{Experiments with Prosodic Features}{
    MFCC vs SDC fed into DNN: SDCs are traditionally preferred because they capture more long-range phenomena whereas MFCCs only capture frame-level stuff. However, with a TDNN that does aggregation over time automatically, it's not so clear whether SDC provide more value. I will compare them with vanilla MFCCs (without any $\Delta$ terms) to see how powerful the TDNN is in terms of context aggregation.

    MFCC/SDC and KaldiPitch concatenatedfed and fed into X-vector DNN
    Two X-vector DNNs trained separately on MFCC/SDC and KaldiPitch
    - evaluated separately
    - the two X-vectors concatenated and classified and evaluated as a whole
  }
}


% use the following and \cite{} as above if you use BibTeX
% otherwise generate bibtem entries
\bibliographystyle{apalike}
\bibliography{s1513472-interim}

\end{document}